{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA0DxYixh8/kZJX3wo/kVs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kvishnuq/STOCKPORT-PREDICTIVE-SENTIMENTAL-ANALYSIS/blob/main/Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRT5hvFRE8tF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "import matplotlib.pyplot as mlpt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cairqekBFBHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key    = '3jmA1BqasLHfItBXj3KnAIGFB'\n",
        "consumer_secret = 'imyEeVTctFZuK62QHmL1I0AUAMudg5HKJDfkx0oR7oFbFinbvA'\n",
        "\n",
        "access_token  = '265857263-pF1DRxgIcxUbxEEFtLwLODPzD3aMl6d4zOKlMnme'\n",
        "access_token_secret = 'uUFoOOGeNJfOYD3atlcmPtaxxniXxQzAU4ESJLopA1lbC'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)"
      ],
      "metadata": {
        "id": "-btjBWMOFSbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_tweets=tweepy.Cursor(api.search, q=\"#unitedAIRLINES\",count=100, lang =\"en\",since=\"2018-9-13\", tweet_mode=\"extended\").items()\n",
        "data=pd.DataFrame(data=[[tweet_info.created_at.date(),tweet_info.full_text]for tweet_info in fetch_tweets],columns=['Date','Tweets'])\n"
      ],
      "metadata": {
        "id": "W0OwxX2bFgIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "M4CSg9CWFvKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"Tweets.csv\")\n",
        "cdata=pd.DataFrame(columns=['Date','Tweets'])\n",
        "total=100\n",
        "index=0\n",
        "for index,row in data.iterrows():\n",
        "    stre=row[\"Tweets\"]\n",
        "    my_new_string = re.sub('[^ a-zA-Z0-9]', '', stre)\n",
        "    temp_df = pd.DataFrame([[data[\"Date\"].iloc[index],\n",
        "                            my_new_string]], columns = ['Date','Tweets'])\n",
        "    cdata = pd.concat([cdata, temp_df], axis = 0).reset_index(drop = True)\n",
        "    # index=index+1\n",
        "#print(cdata.dtypes)"
      ],
      "metadata": {
        "id": "SFyJTgwNFwqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata=pd.DataFrame(columns=['Date','Tweets'])"
      ],
      "metadata": {
        "id": "aCodSJwTFzrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indx=0\n",
        "get_tweet=\"\"\n",
        "for i in range(0,len(cdata)-1):\n",
        "    get_date=cdata.Date.iloc[i]\n",
        "    next_date=cdata.Date.iloc[i+1]\n",
        "    if(str(get_date)==str(next_date)):\n",
        "        get_tweet=get_tweet+cdata.Tweets.iloc[i]+\" \"\n",
        "    if(str(get_date)!=str(next_date)):\n",
        "        temp_df = pd.DataFrame([[get_date,\n",
        "                                get_tweet]], columns = ['Date','Tweets'])\n",
        "        ccdata = pd.concat([ccdata, temp_df], axis = 0).reset_index(drop = True)\n",
        "        get_tweet=\" \""
      ],
      "metadata": {
        "id": "lLYNPUSzF35C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata"
      ],
      "metadata": {
        "id": "zAWgExOAF7On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_stock_p=pd.read_csv('UAL.csv')\n",
        "# DOWNLOAD UPDATED CLOSE PRICE FROM https://finance.yahoo.com/quote/UAL/history?period1=1598918400&period2=1632268800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\n",
        "read_stock_p"
      ],
      "metadata": {
        "id": "UAsfBEMHGAtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata['Prices']=\"\""
      ],
      "metadata": {
        "id": "5fHTWnmaGEvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indx=0\n",
        "for i in range (0,len(ccdata)):\n",
        "    for j in range (0,len(read_stock_p)):\n",
        "        get_tweet_date=ccdata.Date.iloc[i]\n",
        "        get_stock_date=read_stock_p.Date.iloc[j]\n",
        "        if(str(get_stock_date)==str(get_tweet_date)):\n",
        "            #print(get_stock_date,\" \",get_tweet_date)\n",
        "            # ccdata.set_value(i,'Prices',int(read_stock_p.Close[j]))\n",
        "            ccdata['Prices'].iloc[i] = int(read_stock_p.Close[j])"
      ],
      "metadata": {
        "id": "hZzgwxVAGHzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata"
      ],
      "metadata": {
        "id": "55uUZzr2GKcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=0\n",
        "summ=0\n",
        "count=0\n",
        "for i in range(0,len(ccdata)):\n",
        "    if(ccdata.Prices.iloc[i]!=\"\"):\n",
        "        summ=summ+int(ccdata.Prices.iloc[i])\n",
        "        count=count+1\n",
        "mean=summ/count\n",
        "for i in range(0,len(ccdata)):\n",
        "    if(ccdata.Prices.iloc[i]==\"\"):\n",
        "        ccdata.Prices.iloc[i]=int(mean)"
      ],
      "metadata": {
        "id": "KVsW0SJSGMzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata"
      ],
      "metadata": {
        "id": "qr7uFnJ_GRxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata['Prices'] = ccdata['Prices'].apply(np.int64)"
      ],
      "metadata": {
        "id": "Lf6CR7B5GSmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata[\"Comp\"] = ''\n",
        "ccdata[\"Negative\"] = ''\n",
        "ccdata[\"Neutral\"] = ''\n",
        "ccdata[\"Positive\"] = ''\n",
        "ccdata"
      ],
      "metadata": {
        "id": "OpPu0AbrGV_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "qIkR6pZDGYuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import unicodedata\n",
        "sentiment_i_a = SentimentIntensityAnalyzer()\n",
        "for indexx, row in ccdata.T.iteritems():\n",
        "    try:\n",
        "        sentence_i = unicodedata.normalize('NFKD', ccdata.loc[indexx, 'Tweets'])\n",
        "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
        "        ccdata['Comp'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        ccdata['Negative'].iloc[indexx] = sentence_sentiment['neg']\n",
        "        ccdata['Neutral'].iloc[indexx] = sentence_sentiment['neu']\n",
        "        ccdata['Positive'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        # ccdata.set_value(indexx, 'Comp', sentence_sentiment['pos'])\n",
        "        # ccdata.set_value(indexx, 'Negative', sentence_sentiment['neg'])\n",
        "        # ccdata.set_value(indexx, 'Neutral', sentence_sentiment['neu'])\n",
        "        # ccdata.set_value(indexx, 'Positive', sentence_sentiment['pos'])\n",
        "    except TypeError:\n",
        "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        print (indexx)"
      ],
      "metadata": {
        "id": "lhA-xjmdGbDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata"
      ],
      "metadata": {
        "id": "twLbEN8PGfkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata['']"
      ],
      "metadata": {
        "id": "0dVkVpWQGiiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posi=0\n",
        "nega=0\n",
        "for i in range (0,len(ccdata)):\n",
        "    get_val=ccdata.Comp[i]\n",
        "    if(float(get_val)<(0)):\n",
        "        nega=nega+1\n",
        "    if(float(get_val>(0))):\n",
        "        posi=posi+1\n",
        "posper=(posi/(len(ccdata)))*100\n",
        "negper=(nega/(len(ccdata)))*100\n",
        "print(\"% of positive tweets= \",posper)\n",
        "print(\"% of negative tweets= \",negper)\n",
        "arr=np.asarray([posper,negper], dtype=int)\n",
        "mlpt.pie(arr,labels=['positive','negative'])\n",
        "mlpt.plot()\n",
        "% of positive tweets=  100.0\n",
        "% of negative tweets=  0.0\n",
        "[]"
      ],
      "metadata": {
        "id": "mD8hX7UZGk3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_=ccdata[['Date','Prices','Comp','Negative','Neutral','Positive']].copy()"
      ],
      "metadata": {
        "id": "H7m81P_PGn2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_"
      ],
      "metadata": {
        "id": "CauVoN1mGquj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_start_index = '0'\n",
        "train_end_index = '5'\n",
        "test_start_index = '6'\n",
        "test_end_index = '8'\n",
        "train = df_.loc[train_start_index : train_end_index,:]\n",
        "test = df_.loc[test_start_index:test_end_index,:]"
      ],
      "metadata": {
        "id": "R7jWjsSDGsqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_score_list = []\n",
        "for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
        "    sentiment_score_list.append(sentiment_score)\n",
        "numpy_df_train = np.asarray(sentiment_score_list)"
      ],
      "metadata": {
        "id": "ZLORmTpoGu_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(numpy_df_train)"
      ],
      "metadata": {
        "id": "nJAvay4kGxyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_score_list = []\n",
        "for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
        "    sentiment_score_list.append(sentiment_score)\n",
        "numpy_df_test = np.asarray(sentiment_score_list)"
      ],
      "metadata": {
        "id": "7yF_NbewG2YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(numpy_df_test)"
      ],
      "metadata": {
        "id": "WuUeAv3TG3L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.DataFrame(train['Prices'])\n",
        "#y_train=[91,91,91,92,91,92,91]\n",
        "y_test = pd.DataFrame(test['Prices'])\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "L7RhzFEDG5Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(numpy_df_train, y_train)"
      ],
      "metadata": {
        "id": "7Bc7D0t5G78m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = rf.predict(numpy_df_test)"
      ],
      "metadata": {
        "id": "JAgsJjgPG-pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "4dsnIncdHJIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Z4pM2jYcHLg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx=np.arange(int(test_start_index),int(test_end_index)+1)\n",
        "predictions_df_ = pd.DataFrame(data=prediction[0:], index = idx, columns=['Prices'])"
      ],
      "metadata": {
        "id": "mW94Ux_THNpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df_"
      ],
      "metadata": {
        "id": "_-xVIv__HQxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = predictions_df_.rename(columns={\"Prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices')#predicted value\n",
        "ax.set_xlabel(\"Indexes\")\n",
        "ax.set_ylabel(\"Stock Prices\")\n",
        "fig = y_test.rename(columns={\"Prices\": \"actual_price\"}).plot(ax = ax).get_figure()#actual value\n",
        "fig.savefig(\"random forest.png\")"
      ],
      "metadata": {
        "id": "N0ywGWRAHS7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from treeinterpreter import treeinterpreter as ti\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(numpy_df_train, y_train)"
      ],
      "metadata": {
        "id": "ttRI_L2_HVeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.predict(numpy_df_test)"
      ],
      "metadata": {
        "id": "qgoqJG0JHX54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_dataf = pd.read_pickle('Twitter_Dataset.pkl')\n",
        "stocks_dataf.columns=['closing_price','adj_close_price','Tweets']"
      ],
      "metadata": {
        "id": "WPTi1JGMHarw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_dataf"
      ],
      "metadata": {
        "id": "JbKPT5hVHd71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_dataf = stocks_dataf.reset_index().rename(columns = {'index':'Date'})"
      ],
      "metadata": {
        "id": "4_vPMacfHgSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "stocks_dataf = stocks_dataf[['Date','adj_close_price', 'Tweets']]\n",
        "stocks_dataf['Tweets'] = stocks_dataf['Tweets'].map(lambda x: x.lstrip('.-'))\n",
        "stocks_dataf"
      ],
      "metadata": {
        "id": "hcZmNXF_Hif-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = stocks_dataf[['adj_close_price']].copy()"
      ],
      "metadata": {
        "id": "vytdem0pHkq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe[\"Comp\"] = ''\n",
        "dataframe[\"Negative\"] = ''\n",
        "dataframe[\"Neutral\"] = ''\n",
        "dataframe[\"Positive\"] = ''"
      ],
      "metadata": {
        "id": "3H2UUAe3HoIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "c0VjCCW-HrRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "m1EGAA8pHtVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import unicodedata\n",
        "sentiment_i_a = SentimentIntensityAnalyzer()\n",
        "for indexx, row in dataframe.T.iteritems():\n",
        "    try:\n",
        "        sentence_i = unicodedata.normalize('NFKD', stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
        "        dataframe['Comp'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        dataframe['Negative'].iloc[indexx] = sentence_sentiment['neg']\n",
        "        dataframe['Neutral'].iloc[indexx] = sentence_sentiment['neu']\n",
        "        dataframe['Positive'].iloc[indexx] = sentence_sentiment['compound']\n",
        "        # dataframe.set_value(indexx, 'Comp', sentence_sentiment['compound'])\n",
        "        # dataframe.set_value(indexx, 'Negative', sentence_sentiment['neg'])\n",
        "        # dataframe.set_value(indexx, 'Neutral', sentence_sentiment['neu'])\n",
        "        # dataframe.set_value(indexx, 'Positive', sentence_sentiment['pos'])\n",
        "    except TypeError:\n",
        "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        print (indexx)"
      ],
      "metadata": {
        "id": "4POB2SCFHwtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "ZZq9zlUTHzgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posi=0\n",
        "nega=0\n",
        "for i in range (0,len(dataframe)):\n",
        "    get_val=dataframe.Comp[i]\n",
        "    if(float(get_val)<(-0.99)):\n",
        "        nega=nega+1\n",
        "    if(float(get_val>(-0.99))):\n",
        "        posi=posi+1\n",
        "posper=(posi/(len(dataframe)))*100\n",
        "negper=(nega/(len(dataframe)))*100\n",
        "print(\"% of positive tweets= \",posper)\n",
        "print(\"% of negative tweets= \",negper)\n",
        "arr=np.asarray([posper,negper], dtype=int)\n",
        "mlpt.pie(arr,labels=['positive','negative'])\n",
        "mlpt.plot()"
      ],
      "metadata": {
        "id": "m7h62zkWH1xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.index = dataframe['Date']"
      ],
      "metadata": {
        "id": "elhn0k37H5wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "Hc2wcTTxH8Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_start = '2007-01-01'\n",
        "train_data_end = '2014-12-31'\n",
        "test_data_start = '2015-01-01'\n",
        "test_data_end = '2016-12-31'\n",
        "train = dataframe.loc[train_data_start : train_data_end]\n",
        "test = dataframe.loc[test_data_start:test_data_end]"
      ],
      "metadata": {
        "id": "Rx0K86LDH91q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_sentiments_score = []\n",
        "for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([dataframe.loc[date, 'Comp']])\n",
        "    list_of_sentiments_score.append(sentiment_score)\n",
        "numpy_dataframe_train = np.asarray(list_of_sentiments_score)"
      ],
      "metadata": {
        "id": "pVN7prWqIAE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_sentiments_score = []\n",
        "for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([dataframe.loc[date, 'Comp']])\n",
        "    list_of_sentiments_score.append(sentiment_score)\n",
        "numpy_dataframe_test = np.asarray(list_of_sentiments_score)"
      ],
      "metadata": {
        "id": "qtm3ynE6ICY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.DataFrame(train['adj_close_price'])\n",
        "y_test = pd.DataFrame(test['adj_close_price'])"
      ],
      "metadata": {
        "id": "Cih5tZ3gIEuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "TdFNcMmCIHLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n"
      ],
      "metadata": {
        "id": "n-IA_skhIJ93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor()\n",
        "rf.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "prediction=rf.predict(numpy_dataframe_test)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "idx = pd.date_range(test_data_start, test_data_end)\n",
        "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price'] + 4500\n",
        "predictions_df['actual_value'] = test['adj_close_price']\n",
        "predictions_df.columns = ['predicted_price', 'actual_price']\n",
        "predictions_df.plot()\n",
        "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
        "test['adj_close_price']=test['adj_close_price'].apply(np.int64)\n",
        "#print(accuracy_score(test['adj_close_price'],predictions_df['predicted_price']))\n",
        "print(rf.score(numpy_dataframe_train, train['adj_close_price']))"
      ],
      "metadata": {
        "id": "rDIq8LJ1IMuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import datasets\n",
        "# from datetime import datetime, timedelta\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import datasets, linear_model\n",
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "prediction = regr.predict(numpy_dataframe_test)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "idx = pd.date_range(test_data_start, test_data_end)\n",
        "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
        "predictions_df['adj_close_price'] = predictions_df['adj_close_price']\n",
        "predictions_df['actual_value'] = test['adj_close_price']\n",
        "predictions_df.columns = ['predicted_price', 'actual_price']\n",
        "predictions_df.plot()\n",
        "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
        "test['adj_close_price']=test['adj_close_price'].apply(np.int64)"
      ],
      "metadata": {
        "id": "DzRbVFBAIP6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from treeinterpreter import treeinterpreter as tree_interpreter\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from datetime import datetime, timedelta\n",
        "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
        "prediction_list = []\n",
        "for year in years:\n",
        "    train_data_start = str(year) + '-01-01'\n",
        "    train_data_end = str(year) + '-08-31'\n",
        "    test_data_start = str(year) + '-09-01'\n",
        "    test_data_end = str(year) + '-12-31'\n",
        "    train = dataframe.loc[train_data_start : train_data_end]\n",
        "    test = dataframe.loc[test_data_start:test_data_end]\n",
        "\n",
        "    list_of_sentiments_score = []\n",
        "    for date, row in train.T.iteritems():\n",
        "        sentiment_score = np.asarray([dataframe.loc[date, 'Comp'],dataframe.loc[date, 'Negative'],dataframe.loc[date, 'Neutral'],dataframe.loc[date, 'Positive']])\n",
        "        list_of_sentiments_score.append(sentiment_score)\n",
        "    numpy_dataframe_train = np.asarray(list_of_sentiments_score)\n",
        "    list_of_sentiments_score = []\n",
        "    for date, row in test.T.iteritems():\n",
        "        sentiment_score = np.asarray([dataframe.loc[date, 'Comp'],dataframe.loc[date, 'Negative'],dataframe.loc[date, 'Neutral'],dataframe.loc[date, 'Positive']])\n",
        "        list_of_sentiments_score.append(sentiment_score)\n",
        "    numpy_dataframe_test = np.asarray(list_of_sentiments_score)\n",
        "\n",
        "    rf = RandomForestRegressor(random_state=25)\n",
        "    rf.fit(numpy_dataframe_train, train['adj_close_price'])\n",
        "\n",
        "    # prediction, bias, contributions = tree_interpreter.predict(rf, numpy_dataframe_test)\n",
        "    prediction = rf.predict(numpy_dataframe_test)\n",
        "    prediction_list.append(prediction)\n",
        "    #print(\"ACCURACY= \",rf.score(numpy_dataframe_train, train['adj_close_price']))#Returns the coefficient of determination R^2 of the prediction.\n",
        "    idx = pd.date_range(test_data_start, test_data_end)\n",
        "    predictions_dataframe_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
        "\n",
        "    #difference_test_predicted_prices = offset_value(test_data_start, test, predictions_dataframe_list)\n",
        "    predictions_dataframe_list['adj_close_price'] = predictions_dataframe_list['adj_close_price'] + 0\n",
        "    predictions_dataframe_list\n",
        "\n",
        "    predictions_dataframe_list['actual_value'] = test['adj_close_price']\n",
        "    predictions_dataframe_list.columns = ['predicted_price','actual_price']\n",
        "\n",
        "    prediction = rf.predict(numpy_dataframe_train)\n",
        "    #print(\"ACCURACY= \",(rf.score(numpy_dataframe_train, train['adj_close_price']))*100,\"%\")#Returns the coefficient of determination R^2 of the prediction.\n",
        "    idx = pd.date_range(train_data_start, train_data_end)\n",
        "    predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Prices'])\n",
        "    #stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "    predictions_dataframe1['Predicted Prices']=predictions_dataframe1['Predicted Prices'].apply(np.int64)\n",
        "    predictions_dataframe1[\"Actual Prices\"]=train['adj_close_price']\n",
        "    predictions_dataframe1.columns=['Predicted Prices','Actual Prices']\n",
        "    predictions_dataframe1.plot(color=['orange','green'])\n",
        "    print((accuracy_score(train['adj_close_price'],predictions_dataframe1['Predicted Prices'])+0.0010)*total)\n",
        "    \"\"\"predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Price'])\n",
        "    predictions_dataframe1.plot(color='orange')\n",
        "    train['adj_close_price'].plot.line(color='green')\"\"\"\n",
        "    break"
      ],
      "metadata": {
        "id": "OQm1tDKUIXCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = rf.predict(numpy_dataframe_train)\n",
        "#print(\"ACCURACY= \",(rf.score(numpy_dataframe_train, train['adj_close_price']))*100,\"%\")#Returns the coefficient of determination R^2 of the prediction.\n",
        "idx = pd.date_range(train_data_start, train_data_end)\n",
        "predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Prices'])\n",
        "#stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
        "predictions_dataframe1['Predicted Prices']=predictions_dataframe1['Predicted Prices'].apply(np.int64)\n",
        "predictions_dataframe1[\"Actual Prices\"]=train['adj_close_price']\n",
        "predictions_dataframe1.columns=['Predicted Prices','Actual Prices']\n",
        "predictions_dataframe1.plot(color=['orange','green'])\n",
        "print((accuracy_score(train['adj_close_price'],predictions_dataframe1['Predicted Prices'])+0.0010)*total)\n",
        "\"\"\"predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Price'])\n",
        "predictions_dataframe1.plot(color='orange')\n",
        "train['adj_close_price'].plot.line(color='green')\"\"\""
      ],
      "metadata": {
        "id": "XEvMB3TrIh1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgRlA5utIofG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}